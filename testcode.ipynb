{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cade3902-45b8-4acf-8a0a-5089cd138c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tarmi\\anaconda\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator DecisionTreeClassifier from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\tarmi\\anaconda\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator RandomForestClassifier from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n",
      "C:\\Users\\tarmi\\anaconda\\Lib\\site-packages\\sklearn\\base.py:376: InconsistentVersionWarning: Trying to unpickle estimator MultiOutputClassifier from version 1.3.2 when using version 1.4.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'prediction_proba' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 84\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;66;03m# Prepare data for display\u001b[39;00m\n\u001b[0;32m     83\u001b[0m activities \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBathing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDressing\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mToileting\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMobility\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 84\u001b[0m needs_assistance \u001b[38;5;241m=\u001b[39m [prediction_proba[i][\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(activities))]\n\u001b[0;32m     86\u001b[0m \u001b[38;5;66;03m# Identify the highest and lowest probability\u001b[39;00m\n\u001b[0;32m     87\u001b[0m highest_index \u001b[38;5;241m=\u001b[39m needs_assistance\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mmax\u001b[39m(needs_assistance))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'prediction_proba' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Set the page configuration for a wide layout\n",
    "st.set_page_config(layout=\"wide\")\n",
    "\n",
    "# Load the trained model and feature names\n",
    "model = joblib.load('multi_output_rf_model_adl.pkl')\n",
    "feature_names = joblib.load('feature_names_adl.pkl')\n",
    "\n",
    "# Load your dataset to extract unique 'state' and 'gender'\n",
    "file_path = 'ADLprediction.csv'  # Adjust the path if necessary\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Extract unique 'state' options\n",
    "state_options = sorted(data['state'].unique())\n",
    "\n",
    "# Title of the Dashboard\n",
    "st.title('Real-Time ADL Prediction Dashboard for Elderly Individuals')\n",
    "\n",
    "# Sidebar for User Input\n",
    "st.sidebar.header('Input Features')\n",
    "\n",
    "# Function to accept user input\n",
    "def user_input_features():\n",
    "    # Select state\n",
    "    state = st.sidebar.selectbox('State', state_options)\n",
    "\n",
    "    # Filter dataset based on the selected state to get unique gender options\n",
    "    gender_options = sorted(data[data['state'] == state]['gender'].unique())\n",
    "    \n",
    "    # Select gender based on filtered options\n",
    "    gender = st.sidebar.selectbox('Gender', gender_options)\n",
    "\n",
    "    # Create an empty DataFrame with all feature names set to 0\n",
    "    input_df = pd.DataFrame(0, index=[0], columns=feature_names)\n",
    "\n",
    "    # One-hot encode the input features\n",
    "    input_data = {'state_' + state: 1, 'gender_' + gender: 1}\n",
    "    \n",
    "    # Update the DataFrame with user input\n",
    "    for key in input_data.keys():\n",
    "        if key in input_df.columns:\n",
    "            input_df.at[0, key] = input_data[key]\n",
    "\n",
    "    # Ensure all columns expected by the model are present\n",
    "    input_df = input_df.reindex(columns=feature_names, fill_value=0)\n",
    "\n",
    "    # Check for missing or unexpected values\n",
    "    input_df = input_df.fillna(0)\n",
    "\n",
    "    return input_df, state\n",
    "\n",
    "# Get user input DataFrame and the selected state\n",
    "input_df, selected_state = user_input_features()\n",
    "\n",
    "# Calculate the total record count and the record count for the selected state\n",
    "total_record_count = len(data)\n",
    "state_record_count = len(data[data['state'] == selected_state])\n",
    "\n",
    "# Display the record counts side-by-side\n",
    "st.subheader('Record Counts')\n",
    "col_total, col_selected = st.columns(2)\n",
    "\n",
    "with col_total:\n",
    "    st.metric(label=\"Total Records\", value=f\"{total_record_count} records\")\n",
    "\n",
    "with col_selected:\n",
    "    st.metric(label=\"Records for Selected State\", value=f\"{state_record_count} records\")\n",
    "\n",
    "# Predict with the model whenever user input changes\n",
    "try:\n",
    "    prediction = model.predict(input_df)\n",
    "    prediction_proba = model.predict_proba(input_df)\n",
    "except Exception as e:\n",
    "    st.error(f\"An error occurred during prediction: {e}\")\n",
    "    st.stop()\n",
    "\n",
    "# Prepare data for display\n",
    "activities = ['Eating', 'Bathing', 'Dressing', 'Toileting', 'Mobility']\n",
    "needs_assistance = [prediction_proba[i][0][1] * 100 for i in range(len(activities))]\n",
    "\n",
    "# Identify the highest and lowest probability\n",
    "highest_index = needs_assistance.index(max(needs_assistance))\n",
    "lowest_index = needs_assistance.index(min(needs_assistance))\n",
    "\n",
    "# Display scorecards for highest and lowest probabilities\n",
    "st.subheader('Summary of Assistance Needs')\n",
    "col_high, col_low = st.columns(2)\n",
    "\n",
    "with col_high:\n",
    "    st.metric(label=f\"Highest Needs Assistance: {activities[highest_index]}\",\n",
    "              value=f\"{round(needs_assistance[highest_index], 2)}%\",\n",
    "              delta=\"High\")\n",
    "\n",
    "with col_low:\n",
    "    st.metric(label=f\"Lowest Needs Assistance: {activities[lowest_index]}\",\n",
    "              value=f\"{round(needs_assistance[lowest_index], 2)}%\",\n",
    "              delta=\"Low\")\n",
    "\n",
    "# Display the bar chart below the summary\n",
    "st.subheader('Probability of Needs Assistance for Each Activity')\n",
    "fig, ax = plt.subplots(figsize=(8, 4))  # Adjust the figure size to fit the screen better\n",
    "ax.bar(activities, needs_assistance, color='skyblue')\n",
    "ax.set_xlabel('Activities')\n",
    "ax.set_ylabel('Probability of Needs Assistance (%)')\n",
    "ax.set_title('Probability of Needs Assistance')\n",
    "st.pyplot(fig)\n",
    "\n",
    "# Display 360-degree gauge charts without a title\n",
    "gauge_cols = st.columns(len(activities))\n",
    "\n",
    "for i, activity in enumerate(activities):\n",
    "    gauge = go.Figure(go.Indicator(\n",
    "        mode=\"gauge+number\",\n",
    "        value=needs_assistance[i],\n",
    "        title={'text': activity},\n",
    "        gauge={'axis': {'range': [0, 100], 'dtick': 20},\n",
    "               'bar': {'color': \"skyblue\"},\n",
    "               'steps': [\n",
    "                   {'range': [0, 50], 'color': 'lightgray'},\n",
    "                   {'range': [50, 100], 'color': 'lightgreen'}]\n",
    "               }\n",
    "    ))\n",
    "\n",
    "    with gauge_cols[i]:\n",
    "        st.plotly_chart(gauge, use_container_width=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e504b2-d4da-4ee8-b15c-697515e4cea3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c2853d-ec76-4a40-bb08-e8281d9028d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "461aed1a-75bb-4882-a171-cf7eaa8d9018",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
